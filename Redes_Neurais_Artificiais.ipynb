{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes Neurais Artificiais.ipynb",
      "provenance": [],
      "mount_file_id": "1UMZDj_gcdOVI5BtJ-IM5LVJrdneuCDvv",
      "authorship_tag": "ABX9TyNrpuZJaniBUnzRKDk5+pTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rendrikson98/Aprendizado-de-M-quina/blob/master/Redes_Neurais_Artificiais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxZSPD76SSrl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**1. Leitura dos dados com o Pandas**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClckbwMqRpz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "03ecc516-2acd-44f8-bda4-016f9caba06b"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/heart_failure_clinical_records_dataset - heart_failure_clinical_records_dataset.csv')\n",
        "data.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0   75        0                       582  ...        0     4            1\n",
              "1   55        0                      7861  ...        0     6            1\n",
              "2   65        0                       146  ...        1     7            1\n",
              "3   50        1                       111  ...        0     7            1\n",
              "4   65        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_hghWw1SsXY",
        "colab_type": "text"
      },
      "source": [
        "**2. Limpeza dos dados com o Pandas e Re-escala dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV3FxdGHSu6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "11543bbd-3eeb-4a1a-9d7a-a202fc6a184e"
      },
      "source": [
        "#Verificar se existem valores NAN, ? ou dados faltantes\n",
        "data = data.dropna()\n",
        "#Excluir colunas irrelevantes\n",
        "#data = data.drop(columns=['time', 'creatinine_phosphokinase', 'platelets', 'serum_sodium'])\n",
        "data=data[data['ejection_fraction']<70]\n",
        "data['age']=data['age'].astype('int64')\n",
        "data['anaemia'].value_counts(normalize=True)*100\n",
        "data['diabetes'].value_counts(normalize=True)*100\n",
        "data['high_blood_pressure'].value_counts(normalize=True)*100\n",
        "data['sex'].value_counts(normalize=True)*100\n",
        "data['smoking'].value_counts(normalize=True)*100\n",
        "data['DEATH_EVENT'].value_counts(normalize=True)*100\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0   75        0                       582  ...        0     4            1\n",
              "1   55        0                      7861  ...        0     6            1\n",
              "2   65        0                       146  ...        1     7            1\n",
              "3   50        1                       111  ...        0     7            1\n",
              "4   65        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-CwEOlkAGT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU_Yg5a3S8mk",
        "colab_type": "text"
      },
      "source": [
        "**4. Organizando dados da modelagem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTvewjxaTIEV",
        "colab_type": "text"
      },
      "source": [
        "**Dividir os dados em atributos descritores e atributo de classe (target)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jBJoYonTC6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "60a5e095-f870-4aab-a5da-44bf8acd7f10"
      },
      "source": [
        "X = data.iloc[:,[0,4,7,11]]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>20</td>\n",
              "      <td>1.9</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>38</td>\n",
              "      <td>1.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>20</td>\n",
              "      <td>1.3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>1.9</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>20</td>\n",
              "      <td>2.7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  ejection_fraction  serum_creatinine  time\n",
              "0   75                 20               1.9     4\n",
              "1   55                 38               1.1     6\n",
              "2   65                 20               1.3     7\n",
              "3   50                 20               1.9     7\n",
              "4   65                 20               2.7     8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZMop_tmTQnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2dbc4dd6-3a36-47aa-c48b-73188ea96868"
      },
      "source": [
        "y = data.DEATH_EVENT\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: DEATH_EVENT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt5tRZ2DTZ-h",
        "colab_type": "text"
      },
      "source": [
        "**Dividir os dados em treino e teste**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BhIaCGTa1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c199403e-5206-4a94-ad1a-199642fedfdf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)\n",
        "\n",
        "rparams={\n",
        "    'max_leaf_nodes':[2,3,4,5,6,7],\n",
        "    'criterion':['entropy','gini'],\n",
        "    'max_depth':['None',2,3,4,5,6],\n",
        "    'min_samples_split':[2,3,4,5,6],\n",
        "    'min_samples_leaf':[1,2,4,5,5,6],\n",
        "    'max_features':['None','auto','log2','sqrt']\n",
        "}\n",
        "\n",
        "d=DecisionTreeClassifier(random_state=0)\n",
        "classificador=RandomizedSearchCV(d,param_distributions=rparams,cv=10,n_jobs=-1,scoring='roc_auc',random_state=0)\n",
        "classificador.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features=None,\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    presort='deprecated',\n",
              "                                                    random_state=0,\n",
              "                                                    splitter='best'),\n",
              "                   iid...', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
              "                                        'max_depth': ['None', 2, 3, 4, 5, 6],\n",
              "                                        'max_features': ['None', 'auto', 'log2',\n",
              "                                                         'sqrt'],\n",
              "                                        'max_leaf_nodes': [2, 3, 4, 5, 6, 7],\n",
              "                                        'min_samples_leaf': [1, 2, 4, 5, 5, 6],\n",
              "                                        'min_samples_split': [2, 3, 4, 5, 6]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False, scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlUVdn0KU8Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b17e09a4-367a-420b-faa9-33b622ae0447"
      },
      "source": [
        "classificacao = classificador.predict(X_test)\n",
        "print(classification_report(y_test,classificacao))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.84      0.94      0.89        17\n",
            "\n",
            "    accuracy                           0.93        60\n",
            "   macro avg       0.91      0.94      0.92        60\n",
            "weighted avg       0.94      0.93      0.93        60\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zFnMg-_XO8w",
        "colab_type": "text"
      },
      "source": [
        "**6. Avaliação do classificador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZKImCWOXTF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3cb61f4-7474-4b39-b58e-7c5771a4b497"
      },
      "source": [
        "#calculando acurácia\n",
        "from sklearn.metrics import accuracy_score\n",
        "acuracia = accuracy_score(y_test, classificacao)\n",
        "round(acuracia, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyH41E8cYJOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7862c1a7-ff77-457c-c604-473055ccb4a3"
      },
      "source": [
        "#calculando precisão\n",
        "from sklearn.metrics import precision_score\n",
        "precisao = precision_score(y_test, classificacao)\n",
        "round(precisao, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7OKtVlNYlCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4f48e10-5f5d-40a0-8022-dcbd9992d11b"
      },
      "source": [
        "#calculando recall (revocação)\n",
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(y_test, classificacao)\n",
        "round(recall, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTW3JXHQZbpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "591be799-7794-46d9-96ff-4909fecfcaba"
      },
      "source": [
        "#calculando f1-score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_test, classificacao)\n",
        "round(f1, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHdIHrc3VC10",
        "colab_type": "text"
      },
      "source": [
        "**5. Definindo algoritmo de aprendizado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyNBiqFpWJKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fd1dac73-a002-47a0-9143-8b70d741b435"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#definindo modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', max_iter=1000)\n",
        "\n",
        "#treinando modelo\n",
        "classificador.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5R4FORAW_Sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c46dc022-40e3-4d17-ec7e-2924ba9eea99"
      },
      "source": [
        "#realizando classificação\n",
        "classificacao = classificador.predict(X_test)\n",
        "classificacao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeFquv73Zq8f",
        "colab_type": "text"
      },
      "source": [
        "**Curva ROC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdKqEDOYZtre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2f9a512e-2eb5-4791-9754-c38829ff1881"
      },
      "source": [
        "#plotando curva roc \n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, classificacao)\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Poisitivos')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXjxiYARan7W",
        "colab_type": "text"
      },
      "source": [
        "**Área sob a curva (Area under the curve - AUC)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJHs4rQxapvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d383abd-56ac-455a-dc76-ab3f68e922e9"
      },
      "source": [
        "#calculando area sob a curva ROC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc = roc_auc_score(y_test,classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVkbDF-avAy",
        "colab_type": "text"
      },
      "source": [
        "**Validação cruzada**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB1WeekCaybF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f04b901a-5ed2-42c9-e5fa-c9225e7e44df"
      },
      "source": [
        "# avaliando modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#define modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)\n",
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,X,y,cv=10)\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6       , 0.83333333, 1.        , 0.9       , 1.        ,\n",
              "       0.76666667, 0.8       , 0.72413793, 0.68965517, 0.68965517])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaRyH8zCbGCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d79ffdb5-7c80-4598-e73d-98d4fbfe96bf"
      },
      "source": [
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS0Gzq7VbKZt",
        "colab_type": "text"
      },
      "source": [
        "**7. Comparando MLP com Árvore de Decisão e Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ktb93rbMZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "59657926-d07b-403d-9f52-f8760708e4d8"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#criando árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_arvore = cross_val_score(arvore,X,y,cv=10)\n",
        "\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_floresta = cross_val_score(floresta,X,y,cv=10)\n",
        "\n",
        "#criando rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)\n",
        "\n",
        "#calculando os scores\n",
        "scores_mlp = cross_val_score(mlp,X,y,cv=10)\n",
        "\n",
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3),round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(),3),round(scores.std(),3))\n",
        "print('MLP:', round(scores_mlp.mean(),3),round(scores_mlp.std(),3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.694 0.165\n",
            "Random Forest:  0.8 0.127\n",
            "MLP: 0.78 0.129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8wrgkNvbnui",
        "colab_type": "text"
      },
      "source": [
        "**Otimização de Parâmetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvY94_iObu55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "ac0dbd0a-aaef-416a-c9e7-9d7a9cb6f65a"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes': [(10),(50),(100),(50,10),(100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [1000,2000]\n",
        "              }\n",
        "              \n",
        "]\n",
        "\n",
        "mlp = RandomizedSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')\n",
        "\n",
        "mlp.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 50, 100,\n",
              "                                                                (50, 10),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1BLDpIccWgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1ddde6f-0a5b-4fde-df2b-c0850ab6e74a"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': 100, 'activation': 'identity'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvDWZgV-cwH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af353f05-b9f9-4396-fb78-603a927ba421"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQLOefxkc_13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6f6e58c-08fe-4d66-dd05-f958f60f98ad"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "mlp = GridSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')\n",
        "\n",
        "mlp.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 50, 100, (50, 10),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luP6qhdEdPyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70869fb6-cc21-4892-a7a6-3f5790e16451"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'identity', 'hidden_layer_sizes': 100, 'max_iter': 1000, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIYdOEpIdT_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a46f0f7-5ae4-4886-d755-77758ce226c0"
      },
      "source": [
        "print(mlp.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.815084745762712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvGNScvEdYRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea973938-d2aa-4f8d-a2ef-2e66827a2278"
      },
      "source": [
        "mlp.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([1.11287117e-02, 2.25831032e-02, 1.64756632e-01, 3.03421021e-03,\n",
              "        1.88083649e-02, 1.87769794e-01, 7.63545036e-03, 3.96972656e-02,\n",
              "        5.81562042e-02, 5.04541397e-03, 6.33029938e-02, 7.02898979e-02,\n",
              "        5.75795174e-03, 5.74481964e-02, 6.78848267e-02, 2.04475403e-02,\n",
              "        4.91146088e-02, 5.63921928e-02, 1.17413998e-02, 3.80977154e-02,\n",
              "        5.14870167e-02, 1.96013927e-02, 3.58494282e-02, 2.92999744e-02,\n",
              "        1.28683567e-02, 9.60287094e-02, 1.30283165e-01, 3.12252998e-02,\n",
              "        8.36453915e-02, 7.60872364e-02, 1.81328058e-01, 3.79089785e-01,\n",
              "        4.32899523e-01, 1.23570156e-01, 3.84984589e-01, 4.09085321e-01,\n",
              "        1.08612766e+00, 6.04123402e-01, 4.16379690e-01, 1.79981327e+00,\n",
              "        6.83397055e-01, 3.70172453e-01, 1.92776647e+00, 7.56416559e-01,\n",
              "        4.05481720e-01, 3.00897059e+00, 6.84117985e-01, 3.98966455e-01,\n",
              "        6.38227320e-01, 1.04378881e+00, 4.46367836e-01, 1.55018139e+00,\n",
              "        1.28078899e+00, 5.21185970e-01, 3.67831135e+00, 2.71907315e+00,\n",
              "        6.70461369e-01, 6.62226048e+00, 2.80154510e+00, 6.29272032e-01,\n",
              "        8.55818272e-02, 2.01454830e-01, 3.50421715e-01, 8.22188377e-02,\n",
              "        1.88604450e-01, 2.48643494e-01, 9.82276726e-01, 2.45226765e-01,\n",
              "        5.20615578e-01, 1.23093815e+00, 2.60784864e-01, 4.03062248e-01,\n",
              "        1.37478867e+00, 4.30389214e-01, 4.25164843e-01, 1.95009508e+00,\n",
              "        4.12557316e-01, 3.65268373e-01, 9.05390310e-01, 3.79613781e-01,\n",
              "        3.17545700e-01, 9.86046314e-01, 2.27757549e-01, 3.84087467e-01,\n",
              "        2.68213692e+00, 8.03671932e-01, 7.47109890e-01, 4.95385599e+00,\n",
              "        6.75153923e-01, 7.09772062e-01, 4.79693413e-03, 4.00990009e-02,\n",
              "        3.83248520e-01, 3.57208252e-03, 4.70156193e-02, 3.38079548e-01,\n",
              "        5.60245514e-03, 6.39832973e-02, 1.44549656e-01, 2.16024208e-01,\n",
              "        1.07421064e-01, 1.71816683e-01, 2.52992582e-01, 7.94906616e-02,\n",
              "        1.64993763e-01, 8.11203480e-01, 8.03888321e-02, 2.16579056e-01,\n",
              "        1.89444733e-01, 1.15215826e-01, 1.51096773e-01, 8.65887165e-02,\n",
              "        3.12862682e-01, 1.40422010e-01, 1.05278807e+00, 1.56052876e-01,\n",
              "        2.37335396e-01, 1.05191522e+00, 1.34578943e-01, 2.75658035e-01]),\n",
              " 'mean_score_time': array([0.00166321, 0.00136099, 0.00138521, 0.00104828, 0.001263  ,\n",
              "        0.00133467, 0.00153785, 0.00182457, 0.00173006, 0.00151138,\n",
              "        0.00180535, 0.00169892, 0.00150709, 0.00180354, 0.00171971,\n",
              "        0.00166335, 0.00171819, 0.00175467, 0.00155277, 0.00135136,\n",
              "        0.00138311, 0.0011579 , 0.00138121, 0.00133324, 0.00178146,\n",
              "        0.00182929, 0.00182562, 0.00185866, 0.00185995, 0.00195069,\n",
              "        0.00145545, 0.00137019, 0.001337  , 0.00136719, 0.00140033,\n",
              "        0.00134416, 0.00186763, 0.0019495 , 0.00191045, 0.00189228,\n",
              "        0.0018158 , 0.00180607, 0.00200973, 0.00198641, 0.00203524,\n",
              "        0.00242858, 0.00190287, 0.00197206, 0.00173955, 0.00165343,\n",
              "        0.00145884, 0.00181994, 0.00149622, 0.00157542, 0.00215335,\n",
              "        0.00210786, 0.0021946 , 0.00219903, 0.00219536, 0.00227695,\n",
              "        0.00147648, 0.00133595, 0.00139427, 0.00129685, 0.00136914,\n",
              "        0.00136681, 0.00186148, 0.00191231, 0.00185285, 0.00183601,\n",
              "        0.00190067, 0.00200539, 0.00193534, 0.00203094, 0.00207343,\n",
              "        0.00192871, 0.00202117, 0.00205021, 0.00197611, 0.00145636,\n",
              "        0.00144234, 0.00155172, 0.00142436, 0.00149608, 0.00225611,\n",
              "        0.00224214, 0.00227604, 0.00240455, 0.0022984 , 0.00231895,\n",
              "        0.00155268, 0.00143704, 0.00145783, 0.00109062, 0.00139265,\n",
              "        0.00131464, 0.00151591, 0.00190678, 0.00188761, 0.00166683,\n",
              "        0.00186486, 0.0018126 , 0.00168796, 0.00185442, 0.00186701,\n",
              "        0.00186658, 0.00182238, 0.00181484, 0.00147452, 0.00145264,\n",
              "        0.00144057, 0.00129414, 0.00141635, 0.00147266, 0.00181894,\n",
              "        0.0019527 , 0.00195689, 0.00193009, 0.00196328, 0.00318866]),\n",
              " 'mean_test_score': array([0.72016949, 0.69694915, 0.81141243, 0.68011299, 0.80491525,\n",
              "        0.81502825, 0.68011299, 0.77491525, 0.77480226, 0.74050847,\n",
              "        0.70101695, 0.78474576, 0.72677966, 0.75101695, 0.81508475,\n",
              "        0.70412429, 0.67824859, 0.77141243, 0.71677966, 0.7980791 ,\n",
              "        0.80824859, 0.66344633, 0.79485876, 0.74451977, 0.68011299,\n",
              "        0.79485876, 0.6780226 , 0.68689266, 0.78163842, 0.76768362,\n",
              "        0.73757062, 0.72740113, 0.74073446, 0.63672316, 0.73734463,\n",
              "        0.75757062, 0.64728814, 0.75429379, 0.75412429, 0.63344633,\n",
              "        0.75073446, 0.75412429, 0.67028249, 0.75090395, 0.76429379,\n",
              "        0.65016949, 0.7440113 , 0.75751412, 0.63689266, 0.75751412,\n",
              "        0.7340678 , 0.67745763, 0.74751412, 0.72723164, 0.64389831,\n",
              "        0.73745763, 0.75067797, 0.61316384, 0.74062147, 0.73717514,\n",
              "        0.74050847, 0.71084746, 0.74762712, 0.77757062, 0.77429379,\n",
              "        0.73045198, 0.62361582, 0.74079096, 0.72711864, 0.65067797,\n",
              "        0.75418079, 0.69711864, 0.62672316, 0.74418079, 0.73723164,\n",
              "        0.59649718, 0.75429379, 0.72062147, 0.61689266, 0.75451977,\n",
              "        0.70050847, 0.59683616, 0.76768362, 0.66033898, 0.6199435 ,\n",
              "        0.74389831, 0.67734463, 0.65706215, 0.73740113, 0.65039548,\n",
              "        0.72344633, 0.69649718, 0.76774011, 0.67677966, 0.73384181,\n",
              "        0.74774011, 0.71740113, 0.66711864, 0.76412429, 0.67677966,\n",
              "        0.74378531, 0.75418079, 0.63011299, 0.7239548 , 0.80062147,\n",
              "        0.66361582, 0.68372881, 0.73050847, 0.72711864, 0.69683616,\n",
              "        0.73096045, 0.67011299, 0.74079096, 0.72418079, 0.73435028,\n",
              "        0.72384181, 0.72384181, 0.69022599, 0.76079096, 0.73056497]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 100,\n",
              "                    100, 100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), 10, 10, 10,\n",
              "                    10, 10, 10, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
              "                    100, 100, (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000, 1000, 1000, 1000, 2000, 2000, 2000,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 1000, 1000, 1000,\n",
              "                    2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([ 75,  83,   3,  89,   5,   2,  89,  13,  14,  49,  80,  10,  68,\n",
              "         33,   1,  79,  92,  16,  77,   7,   4, 102,   8,  40,  89,   8,\n",
              "         93,  87,  11,  18,  51,  64,  47, 111,  54,  23, 108,  28,  31,\n",
              "        112,  35,  31,  98,  34,  20, 107,  42,  24, 110,  24,  58,  94,\n",
              "         39,  65, 109,  52,  36, 118,  48,  56,  49,  78,  38,  12,  15,\n",
              "         63, 115,  45,  66, 105,  29,  82, 114,  41,  55, 120,  27,  74,\n",
              "        117,  26,  81, 119,  18, 103, 116,  43,  95, 104,  53, 106,  73,\n",
              "         85,  17,  96,  59,  37,  76, 100,  21,  96,  44,  30, 113,  70,\n",
              "          6, 101,  88,  62,  66,  84,  60,  99,  46,  69,  57,  71,  71,\n",
              "         86,  22,  61], dtype=int32),\n",
              " 'split0_test_score': array([0.68333333, 0.56666667, 0.63333333, 0.68333333, 0.6       ,\n",
              "        0.66666667, 0.68333333, 0.46666667, 0.56666667, 0.86666667,\n",
              "        0.65      , 0.63333333, 0.91666667, 0.51666667, 0.7       ,\n",
              "        0.6       , 0.41666667, 0.6       , 0.68333333, 0.61666667,\n",
              "        0.61666667, 0.6       , 0.65      , 0.38333333, 0.68333333,\n",
              "        0.58333333, 0.56666667, 0.68333333, 0.58333333, 0.71666667,\n",
              "        0.53333333, 0.53333333, 0.53333333, 0.51666667, 0.48333333,\n",
              "        0.56666667, 0.5       , 0.53333333, 0.58333333, 0.56666667,\n",
              "        0.58333333, 0.58333333, 0.65      , 0.53333333, 0.58333333,\n",
              "        0.65      , 0.56666667, 0.58333333, 0.53333333, 0.58333333,\n",
              "        0.53333333, 0.63333333, 0.51666667, 0.51666667, 0.56666667,\n",
              "        0.48333333, 0.6       , 0.58333333, 0.55      , 0.58333333,\n",
              "        0.55      , 0.53333333, 0.56666667, 0.61666667, 0.61666667,\n",
              "        0.56666667, 0.5       , 0.51666667, 0.55      , 0.56666667,\n",
              "        0.53333333, 0.55      , 0.56666667, 0.58333333, 0.58333333,\n",
              "        0.55      , 0.55      , 0.51666667, 0.6       , 0.46666667,\n",
              "        0.55      , 0.5       , 0.58333333, 0.61666667, 0.5       ,\n",
              "        0.58333333, 0.56666667, 0.55      , 0.55      , 0.48333333,\n",
              "        0.9       , 0.63333333, 0.61666667, 0.35      , 0.6       ,\n",
              "        0.53333333, 0.68333333, 0.51666667, 0.58333333, 0.66666667,\n",
              "        0.61666667, 0.61666667, 0.68333333, 0.58333333, 0.88333333,\n",
              "        0.65      , 0.48333333, 0.53333333, 0.68333333, 0.46666667,\n",
              "        0.45      , 0.8       , 0.58333333, 0.58333333, 0.68333333,\n",
              "        0.56666667, 0.58333333, 0.68333333, 0.61666667, 0.61666667]),\n",
              " 'split1_test_score': array([0.86666667, 0.83333333, 1.        , 0.68333333, 0.95      ,\n",
              "        0.9       , 0.68333333, 0.93333333, 0.86666667, 0.68333333,\n",
              "        0.55      , 0.86666667, 0.68333333, 0.93333333, 0.85      ,\n",
              "        0.68333333, 0.5       , 0.83333333, 0.86666667, 0.95      ,\n",
              "        0.95      , 0.68333333, 0.86666667, 0.98333333, 0.68333333,\n",
              "        0.93333333, 0.41666667, 0.68333333, 0.83333333, 0.81666667,\n",
              "        0.88333333, 0.88333333, 0.95      , 0.65      , 1.        ,\n",
              "        0.95      , 0.55      , 0.95      , 0.95      , 0.56666667,\n",
              "        0.95      , 0.95      , 0.61666667, 0.95      , 0.95      ,\n",
              "        0.55      , 0.95      , 0.95      , 0.58333333, 0.95      ,\n",
              "        0.91666667, 0.51666667, 0.96666667, 0.95      , 0.48333333,\n",
              "        0.96666667, 0.95      , 0.53333333, 0.96666667, 0.95      ,\n",
              "        1.        , 0.76666667, 0.88333333, 1.        , 0.96666667,\n",
              "        0.95      , 0.53333333, 0.95      , 0.95      , 0.48333333,\n",
              "        0.98333333, 0.8       , 0.55      , 0.88333333, 0.93333333,\n",
              "        0.48333333, 0.93333333, 0.9       , 0.41666667, 0.95      ,\n",
              "        0.8       , 0.43333333, 0.95      , 0.58333333, 0.61666667,\n",
              "        0.96666667, 0.61666667, 0.61666667, 0.91666667, 0.65      ,\n",
              "        0.68333333, 0.9       , 0.9       , 1.        , 0.91666667,\n",
              "        0.88333333, 0.68333333, 0.68333333, 1.        , 0.68333333,\n",
              "        0.96666667, 0.9       , 0.43333333, 0.85      , 0.93333333,\n",
              "        0.58333333, 0.81666667, 0.96666667, 0.81666667, 0.96666667,\n",
              "        0.91666667, 0.51666667, 0.88333333, 0.78333333, 0.68333333,\n",
              "        0.9       , 0.88333333, 0.7       , 0.95      , 0.86666667]),\n",
              " 'split2_test_score': array([0.6779661 , 0.72881356, 0.83050847, 0.6779661 , 0.89830508,\n",
              "        0.91525424, 0.6779661 , 0.88135593, 0.83050847, 0.79661017,\n",
              "        0.84745763, 0.84745763, 0.6779661 , 0.84745763, 0.93220339,\n",
              "        0.88135593, 0.93220339, 0.83050847, 0.6779661 , 0.83050847,\n",
              "        0.89830508, 0.6779661 , 0.84745763, 0.91525424, 0.6779661 ,\n",
              "        0.88135593, 0.83050847, 0.6779661 , 0.84745763, 0.84745763,\n",
              "        0.89830508, 0.86440678, 0.77966102, 0.72881356, 0.79661017,\n",
              "        0.83050847, 0.81355932, 0.88135593, 0.79661017, 0.71186441,\n",
              "        0.81355932, 0.79661017, 0.76271186, 0.86440678, 0.84745763,\n",
              "        0.74576271, 0.81355932, 0.83050847, 0.71186441, 0.88135593,\n",
              "        0.79661017, 0.81355932, 0.88135593, 0.74576271, 0.69491525,\n",
              "        0.86440678, 0.79661017, 0.61016949, 0.83050847, 0.77966102,\n",
              "        0.79661017, 0.81355932, 0.84745763, 0.88135593, 0.89830508,\n",
              "        0.77966102, 0.71186441, 0.79661017, 0.74576271, 0.72881356,\n",
              "        0.83050847, 0.74576271, 0.74576271, 0.81355932, 0.76271186,\n",
              "        0.69491525, 0.86440678, 0.77966102, 0.74576271, 0.91525424,\n",
              "        0.79661017, 0.69491525, 0.88135593, 0.76271186, 0.6440678 ,\n",
              "        0.72881356, 0.77966102, 0.77966102, 0.81355932, 0.72881356,\n",
              "        0.6779661 , 0.49152542, 0.89830508, 0.6779661 , 0.77966102,\n",
              "        0.93220339, 0.86440678, 0.71186441, 0.79661017, 0.6779661 ,\n",
              "        0.77966102, 0.88135593, 0.6779661 , 0.77966102, 0.79661017,\n",
              "        0.6779661 , 0.74576271, 0.76271186, 0.76271186, 0.69491525,\n",
              "        0.88135593, 0.6779661 , 0.86440678, 0.89830508, 0.71186441,\n",
              "        0.81355932, 0.77966102, 0.71186441, 0.83050847, 0.74576271]),\n",
              " 'split3_test_score': array([0.69491525, 0.6779661 , 0.91525424, 0.6779661 , 0.89830508,\n",
              "        0.91525424, 0.6779661 , 0.91525424, 0.93220339, 0.6779661 ,\n",
              "        0.77966102, 0.89830508, 0.6779661 , 0.77966102, 0.91525424,\n",
              "        0.6779661 , 0.86440678, 0.91525424, 0.6779661 , 0.91525424,\n",
              "        0.89830508, 0.6779661 , 0.93220339, 0.76271186, 0.6779661 ,\n",
              "        0.89830508, 0.89830508, 0.71186441, 0.96610169, 0.77966102,\n",
              "        0.6779661 , 0.6779661 , 0.76271186, 0.61016949, 0.72881356,\n",
              "        0.76271186, 0.6779661 , 0.72881356, 0.76271186, 0.62711864,\n",
              "        0.72881356, 0.76271186, 0.62711864, 0.72881356, 0.76271186,\n",
              "        0.61016949, 0.71186441, 0.74576271, 0.66101695, 0.69491525,\n",
              "        0.74576271, 0.72881356, 0.69491525, 0.74576271, 0.77966102,\n",
              "        0.69491525, 0.72881356, 0.62711864, 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.76271186, 0.76271186, 0.71186441, 0.71186441,\n",
              "        0.6779661 , 0.69491525, 0.76271186, 0.71186441, 0.79661017,\n",
              "        0.74576271, 0.71186441, 0.59322034, 0.76271186, 0.72881356,\n",
              "        0.54237288, 0.74576271, 0.72881356, 0.62711864, 0.76271186,\n",
              "        0.6779661 , 0.6779661 , 0.74576271, 0.66101695, 0.66101695,\n",
              "        0.76271186, 0.72881356, 0.66101695, 0.72881356, 0.69491525,\n",
              "        0.6779661 , 0.77966102, 0.74576271, 0.6779661 , 0.69491525,\n",
              "        0.69491525, 0.6779661 , 0.74576271, 0.76271186, 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.71186441, 0.71186441,\n",
              "        0.72881356, 0.69491525, 0.71186441, 0.6779661 , 0.6779661 ,\n",
              "        0.72881356, 0.6779661 , 0.69491525, 0.6779661 , 0.89830508,\n",
              "        0.66101695, 0.69491525, 0.6779661 , 0.72881356, 0.74576271]),\n",
              " 'split4_test_score': array([0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.69491525, 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.6779661 ,\n",
              "        0.69491525, 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.71186441, 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.71186441, 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.69491525, 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ]),\n",
              " 'std_fit_time': array([1.04977785e-02, 6.08761422e-03, 9.11301962e-02, 1.06349717e-04,\n",
              "        8.44680287e-03, 1.35874313e-01, 5.50715998e-03, 1.72391935e-02,\n",
              "        1.94159686e-02, 2.36324411e-04, 1.50890022e-02, 2.07314590e-02,\n",
              "        4.46435860e-04, 1.03756209e-02, 3.89049529e-02, 1.70088676e-02,\n",
              "        1.62853086e-02, 4.17161959e-02, 1.20911710e-02, 1.08149876e-02,\n",
              "        2.27227330e-02, 3.17343217e-02, 7.80111295e-03, 2.19828765e-02,\n",
              "        3.15120549e-03, 2.23779245e-02, 1.80361597e-02, 3.13855904e-02,\n",
              "        1.57294431e-02, 3.77848433e-02, 1.15366263e-01, 1.00935003e-01,\n",
              "        4.26821585e-02, 5.94393240e-02, 7.01951796e-02, 1.66049144e-02,\n",
              "        8.59658624e-02, 8.25630084e-02, 5.19509518e-02, 6.64227615e-01,\n",
              "        9.11168089e-02, 1.04107881e-01, 6.64830699e-02, 9.57133040e-02,\n",
              "        3.55808821e-02, 1.31088556e+00, 1.56363704e-01, 6.02553080e-02,\n",
              "        4.51851966e-01, 8.06761763e-02, 4.71955733e-02, 4.91112215e-01,\n",
              "        2.98862466e-01, 1.25993427e-01, 8.23032855e-02, 4.14887863e-01,\n",
              "        1.37815466e-01, 1.58350187e+00, 8.21591377e-01, 1.92147950e-01,\n",
              "        5.97062577e-02, 9.02860175e-02, 6.49228258e-02, 5.47154027e-02,\n",
              "        9.60131093e-02, 7.70889371e-02, 4.04648685e-02, 1.05953582e-01,\n",
              "        2.07205587e-01, 5.64339368e-01, 1.55585702e-01, 9.82398559e-02,\n",
              "        2.74935143e-01, 5.08463422e-02, 1.03483835e-01, 8.83231669e-01,\n",
              "        1.28530564e-01, 7.03037900e-02, 2.92916366e-02, 6.85084570e-02,\n",
              "        8.16637124e-02, 6.12965532e-01, 6.83186381e-02, 1.53824785e-01,\n",
              "        7.43485210e-01, 1.40588615e-01, 3.05953620e-01, 2.24346677e+00,\n",
              "        1.68654273e-01, 1.98504468e-01, 1.30942679e-04, 2.19785346e-02,\n",
              "        9.44201055e-02, 9.95332329e-04, 1.33653511e-02, 9.66615083e-02,\n",
              "        4.23771398e-04, 1.39235321e-02, 9.79476442e-02, 4.19333728e-01,\n",
              "        4.71651958e-02, 7.41545509e-02, 4.90413604e-01, 2.35648850e-02,\n",
              "        7.50711182e-02, 1.02738979e+00, 6.33586751e-03, 9.52833028e-02,\n",
              "        1.66091762e-01, 4.48902584e-02, 7.39869709e-02, 1.62652997e-01,\n",
              "        2.78296838e-01, 5.04319687e-02, 1.27480943e+00, 3.56642887e-02,\n",
              "        7.96229989e-02, 2.07109426e+00, 5.76681055e-02, 1.06894985e-01]),\n",
              " 'std_score_time': array([2.29131890e-04, 5.07350255e-05, 1.54902296e-04, 1.11923748e-05,\n",
              "        4.83501122e-05, 5.53435209e-05, 8.23797984e-05, 2.44379644e-04,\n",
              "        6.65656133e-05, 3.02054416e-05, 2.20520560e-05, 6.22511595e-05,\n",
              "        6.38143528e-05, 1.32603741e-04, 6.20280655e-05, 1.71901522e-04,\n",
              "        4.67136413e-05, 5.04908634e-05, 1.21800900e-04, 5.45837976e-05,\n",
              "        2.88285035e-05, 1.53568855e-04, 5.92039756e-05, 5.43274283e-05,\n",
              "        7.04956609e-05, 4.68521566e-05, 2.05346920e-05, 8.47423482e-05,\n",
              "        3.10930736e-05, 1.49107322e-04, 1.98283867e-04, 4.53379117e-05,\n",
              "        1.81901970e-05, 4.04037830e-05, 2.78893082e-05, 3.73170091e-05,\n",
              "        2.40344849e-05, 8.40945827e-05, 5.54092164e-05, 5.90846073e-05,\n",
              "        5.38549521e-05, 3.74556726e-05, 6.83732942e-05, 8.01009220e-05,\n",
              "        1.43764039e-04, 7.62497929e-04, 5.37189175e-05, 5.77064775e-05,\n",
              "        2.64636907e-04, 2.41990606e-04, 2.17499431e-05, 3.01744257e-04,\n",
              "        6.13744440e-05, 2.09343210e-04, 9.25957602e-05, 8.06623296e-05,\n",
              "        7.11472999e-05, 8.39838168e-05, 8.34028948e-05, 2.33305433e-04,\n",
              "        1.78121332e-04, 6.35238732e-05, 5.80990416e-05, 4.27772632e-05,\n",
              "        5.35576653e-05, 1.94695596e-05, 6.37495080e-05, 4.80973424e-05,\n",
              "        5.62072698e-05, 8.97408799e-05, 2.24341621e-05, 1.80791247e-04,\n",
              "        6.50306244e-05, 6.22521091e-05, 1.03002080e-04, 5.52039879e-05,\n",
              "        5.64357677e-05, 5.45782570e-05, 1.54187092e-04, 9.49376196e-05,\n",
              "        6.60794802e-05, 1.96110295e-04, 2.19875193e-05, 5.83737108e-05,\n",
              "        1.75932648e-04, 9.16473575e-05, 7.87225656e-05, 4.64200339e-04,\n",
              "        9.04514214e-05, 5.53621289e-05, 2.97725911e-05, 1.68345777e-04,\n",
              "        2.49801312e-04, 2.79015346e-05, 2.96994915e-05, 5.56199426e-05,\n",
              "        6.15048589e-05, 2.22454863e-04, 7.32604702e-05, 1.11691549e-04,\n",
              "        3.15644589e-05, 4.26233744e-05, 1.01632938e-04, 5.20283751e-05,\n",
              "        2.73179837e-05, 2.55663836e-04, 5.17190516e-05, 4.85576181e-05,\n",
              "        1.00282675e-04, 4.68375468e-05, 2.76924591e-05, 7.13783975e-05,\n",
              "        5.87982175e-05, 8.38350243e-05, 1.02486317e-04, 2.92497525e-05,\n",
              "        5.06088911e-05, 9.36867437e-05, 8.72890240e-05, 2.40940807e-03]),\n",
              " 'std_test_score': array([0.07350966, 0.08638313, 0.13873222, 0.0026294 , 0.13899587,\n",
              "        0.11671151, 0.0026294 , 0.17918553, 0.13342791, 0.07766001,\n",
              "        0.10350841, 0.10757988, 0.09496626, 0.14395627, 0.10678558,\n",
              "        0.09386553, 0.19967256, 0.1150056 , 0.07497233, 0.13053677,\n",
              "        0.13415735, 0.0317912 , 0.11084631, 0.21042726, 0.0026294 ,\n",
              "        0.13839437, 0.17463298, 0.0127145 , 0.13498451, 0.06254383,\n",
              "        0.13723512, 0.13087044, 0.13619504, 0.07138145, 0.16770246,\n",
              "        0.13050412, 0.11136819, 0.14815154, 0.12265049, 0.06146041,\n",
              "        0.12446093, 0.12265049, 0.05347731, 0.14537332, 0.12775342,\n",
              "        0.06748956, 0.12970334, 0.12584428, 0.06806247, 0.13636206,\n",
              "        0.12714747, 0.09926385, 0.15927058, 0.13933933, 0.10524525,\n",
              "        0.1664819 , 0.11858158, 0.05866562, 0.14378042, 0.12333562,\n",
              "        0.15139341, 0.09894228, 0.11507319, 0.14168604, 0.1344685 ,\n",
              "        0.12880841, 0.08860832, 0.14250852, 0.12964828, 0.112435  ,\n",
              "        0.15032628, 0.08387964, 0.07404312, 0.10466757, 0.11521551,\n",
              "        0.09043583, 0.13550991, 0.12581453, 0.11240587, 0.17483425,\n",
              "        0.09252375, 0.10853024, 0.13317315, 0.06103855, 0.06329741,\n",
              "        0.12675599, 0.07662617, 0.07560052, 0.12382379, 0.08720474,\n",
              "        0.08830131, 0.13760532, 0.11480893, 0.20555318, 0.10777322,\n",
              "        0.14419669, 0.07354201, 0.07899804, 0.13914258, 0.00546711,\n",
              "        0.12311511, 0.1146019 , 0.09841179, 0.08916776, 0.09735701,\n",
              "        0.04752531, 0.11120915, 0.14056606, 0.05414039, 0.15906121,\n",
              "        0.16664776, 0.09011262, 0.11527675, 0.10763633, 0.08264063,\n",
              "        0.11818334, 0.10122973, 0.0135046 , 0.11774117, 0.08333676])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HjZblDDBHU4",
        "colab_type": "text"
      },
      "source": [
        "Análise e Interpretação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR5qZeEBBV2g",
        "colab_type": "text"
      },
      "source": [
        "Para melhorar a precisão e acurácia dos dados, foi decido utilizar apenas 4 classes diferente das 11 utilizadas na atividade passada. As 4 classes escolhidas para realizar o treinamento da rede neural artificial foram: idade, o tempo desde o início dos acompanhamentos, ejeção fração e soro creatinina. Todas essas classes foram analisadas diretamente relacionadas com os eventos de morte em paciente do estudo. O intuito é investigar como esses fatores influenciam ou não os eventos de mortes por doenças cardiovasculares nos seres humanos.\n",
        " \n",
        "Nossa acurácia e precisão saíram da faixa de 70% para 93% de acurácia e mais de 80% de precisão em nossos dados, sabemos que melhorias precisam ser aplicadas em nossa precisão para obtermos resultados mais confiáveis na investigação, o que será aplicado em atividades futuras.\n",
        " \n",
        "Com o uso da redes neurais artificiais conseguimos obter a melhor pontuação na faixa de 81% nos testes."
      ]
    }
  ]
}